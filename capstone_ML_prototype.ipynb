{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "data = pd.read_csv('../data/accepted_2007_to_2018Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>...</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>annual_inc_joint</th>\n",
       "      <th>dti_joint</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>open_acc_6m</th>\n",
       "      <th>open_act_il</th>\n",
       "      <th>open_il_12m</th>\n",
       "      <th>open_il_24m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1729351</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>14.99</td>\n",
       "      <td>415.93</td>\n",
       "      <td>C4</td>\n",
       "      <td>4 years</td>\n",
       "      <td>Jan-2017</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911200</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>28625.0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>670.97</td>\n",
       "      <td>C1</td>\n",
       "      <td>3 years</td>\n",
       "      <td>Sep-2012</td>\n",
       "      <td>OWN</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7438.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734562</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>8.24</td>\n",
       "      <td>188.69</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan-2017</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>46498.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229044</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>18.25</td>\n",
       "      <td>290.23</td>\n",
       "      <td>E1</td>\n",
       "      <td>3 years</td>\n",
       "      <td>Jul-2015</td>\n",
       "      <td>RENT</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>37354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658378</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>18600.0</td>\n",
       "      <td>12.79</td>\n",
       "      <td>421.22</td>\n",
       "      <td>C1</td>\n",
       "      <td>9 years</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>RENT</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100621.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loan_status  loan_amnt  int_rate  installment sub_grade emp_length  \\\n",
       "1729351   Fully Paid    12000.0     14.99       415.93        C4    4 years   \n",
       "1911200  Charged Off    28625.0     14.33       670.97        C1    3 years   \n",
       "1734562  Charged Off     6000.0      8.24       188.69        B1        NaN   \n",
       "229044   Charged Off     8000.0     18.25       290.23        E1    3 years   \n",
       "658378    Fully Paid    18600.0     12.79       421.22        C1    9 years   \n",
       "\n",
       "          issue_d home_ownership  annual_inc verification_status  ...  \\\n",
       "1729351  Jan-2017       MORTGAGE     35000.0     Source Verified  ...   \n",
       "1911200  Sep-2012            OWN     72000.0            Verified  ...   \n",
       "1734562  Jan-2017       MORTGAGE     46498.0        Not Verified  ...   \n",
       "229044   Jul-2015           RENT     40000.0            Verified  ...   \n",
       "658378   Jun-2016           RENT    115000.0        Not Verified  ...   \n",
       "\n",
       "        mths_since_last_major_derog annual_inc_joint  dti_joint  \\\n",
       "1729351                         NaN              NaN        NaN   \n",
       "1911200                         NaN              NaN        NaN   \n",
       "1734562                         NaN              NaN        NaN   \n",
       "229044                          NaN              NaN        NaN   \n",
       "658378                          NaN              NaN        NaN   \n",
       "\n",
       "         acc_now_delinq tot_coll_amt  tot_cur_bal  open_acc_6m  open_act_il  \\\n",
       "1729351             0.0          0.0      98400.0          0.0          0.0   \n",
       "1911200             0.0          0.0       7438.0          NaN          NaN   \n",
       "1734562             0.0         89.0      71738.0          0.0          2.0   \n",
       "229044              0.0        120.0      37354.0          NaN          NaN   \n",
       "658378              0.0          0.0     100621.0          2.0          3.0   \n",
       "\n",
       "         open_il_12m  open_il_24m  \n",
       "1729351          0.0          0.0  \n",
       "1911200          NaN          NaN  \n",
       "1734562          0.0          2.0  \n",
       "229044           NaN          NaN  \n",
       "658378           3.0          5.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is big data set. For the purpose of prototyping, I will downsample the number of rows and columns.\n",
    "# Later on, I will scale up using the entire data set.\n",
    "\n",
    "select_columns = ['loan_status','loan_amnt','int_rate','installment','sub_grade','emp_length', 'issue_d', \\\n",
    "                  'home_ownership','annual_inc','verification_status','purpose','addr_state', \\\n",
    "                  'dti','delinq_2yrs','earliest_cr_line','fico_range_low','fico_range_high','inq_last_6mths', \\\n",
    "                  'mths_since_last_delinq','mths_since_last_record','open_acc','pub_rec','revol_bal','revol_util', \\\n",
    "                  'total_acc','collections_12_mths_ex_med','mths_since_last_major_derog','annual_inc_joint', \\\n",
    "                  'dti_joint','acc_now_delinq','tot_coll_amt', 'tot_cur_bal','open_acc_6m','open_act_il', \\\n",
    "                  'open_il_12m','open_il_24m']\n",
    "\n",
    "data_fully_paid = data[data.loan_status == 'Fully Paid']\n",
    "data_charged_off = data[data.loan_status == 'Charged Off']\n",
    "\n",
    "# The data are combined in balance: the number of fully paid = charged off\n",
    "combined_data = pd.concat([data_fully_paid[select_columns].sample(n=10000, random_state=34), \\\n",
    "                           data_charged_off[select_columns].sample(n=10000, random_state=34)])\n",
    "minidata = combined_data.sample(frac=1, random_state=34)\n",
    "minidata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "# Change some columns to categorical\n",
    "categorical_columns = ['sub_grade','home_ownership','verification_status','purpose','addr_state']\n",
    "minidata[categorical_columns] = minidata[categorical_columns].astype('category')\n",
    "minidata['sub_grade'] = pd.Categorical(minidata['sub_grade'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Change employment length to float\n",
    "minidata['emp_length'] = minidata['emp_length'].astype('str')\n",
    "minidata['emp_length'] = minidata['emp_length'].map(lambda x: x.rstrip(' years'))\n",
    "minidata['emp_length'][minidata.emp_length == '< 1'] = '0'\n",
    "minidata['emp_length'][minidata.emp_length == '10+'] = '10'\n",
    "minidata['emp_length'] = minidata['emp_length'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datetime format\n",
    "date_columns = ['earliest_cr_line','issue_d']\n",
    "minidata[date_columns] = minidata[date_columns].apply(pd.to_datetime)\n",
    "\n",
    "# Convert into time interval and then to float that count days\n",
    "minidata['time_interval'] = (minidata['issue_d'] - minidata['earliest_cr_line']).dt.days\n",
    "minidata = minidata.drop(date_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding for categorical variables\n",
    "\n",
    "#def cat2ohe(data, col):\n",
    "#    label_encoded = LabelEncoder().fit_transform(data[col])\n",
    "#    label_encoded = label_encoded.reshape(len(label_encoded), 1)\n",
    "#    return OneHotEncoder(sparse=False).fit_transform(label_encoded)\n",
    "\n",
    "minidata['sub_grade'] = LabelEncoder().fit_transform(minidata['sub_grade'])\n",
    "minidata['loan_status'] = LabelEncoder().fit_transform(minidata['loan_status'])\n",
    "\n",
    "for cat_col in categorical_columns[1:]:\n",
    "    ohe_col = pd.get_dummies(minidata[cat_col], prefix=cat_col, dummy_na=True)\n",
    "    minidata = pd.concat([minidata, ohe_col], axis=1)\n",
    "    minidata = minidata.drop(cat_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_dict = {}\n",
    "for col in minidata.columns:\n",
    "    if minidata[col].isna().sum() > 0:\n",
    "        na_dict[col] = np.nanmedian(minidata[col])\n",
    "\n",
    "minidata = minidata.fillna(value=na_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=34, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling using Random Forest\n",
    "\n",
    "y = minidata['loan_status']\n",
    "X = minidata.drop('loan_status', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=34)\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=34)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6441497684879482"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2047, 1019],\n",
       "       [1113, 1821]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_rate 0.07311868874429552\n",
      "sub_grade 0.06698188103801757\n",
      "dti 0.054879836157248806\n",
      "tot_cur_bal 0.04851251745848959\n",
      "installment 0.048383017574374\n",
      "revol_util 0.04802534070789761\n",
      "revol_bal 0.04773019279748678\n",
      "time_interval 0.046560813207806126\n",
      "annual_inc 0.04496929850185367\n",
      "loan_amnt 0.042811041489926885\n"
     ]
    }
   ],
   "source": [
    "importance = rfc.feature_importances_\n",
    "ind = np.argsort(importance)[::-1]\n",
    "for i in ind[:10]:\n",
    "    print(X.columns[i], importance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'ccp_alpha': [0, 1, 10],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'min_samples_split': [0.01, 0.05, 0.1],\n",
       "                         'n_estimators': [10, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'n_estimators': [10, 50, 100], \\\n",
    "              'criterion': ['gini', 'entropy'], \\\n",
    "              'min_samples_split': [0.01, 0.05, 0.10], \\\n",
    "              'max_features': ['sqrt', 'log2', None], \\\n",
    "              'ccp_alpha': [0, 1, 10]}\n",
    "\n",
    "gs  = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6441497684879482"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some problems:\n",
    "\n",
    "1) It took so long to do hyperparameter tuning --> Move to domino/colab? But data size is too large.\n",
    "\n",
    "2) ROC-AUC score is low --> Maybe not choosing optimal features? Replace features that aren't important.\n",
    "\n",
    "3) Replacing NaN value with median doesn't seem optimal --> Do some kind of prediction for missing value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
